# PepperBots

# üìù Description of the project

Projet realis√© en IML (Interactive Machine Learning). 
Ce projet consistait √† cr√©er une application avec QiBullet (simulateur de robot Pepper et Nao) en int√©grant du machine learning et des interactions homme / machine

# Objectif

L'objectif √©tait de pouvoir int√©ragir avec le robot en utilisant diff√©rent moyen. On a souhait√© interagir avec celui-ci en mettant en place un syst√®me de discution dans la console. On peut discuter avec lui, dire bonjour, demander une blague ou plus int√©ressant, lui donner des taches √† faire.

Parmi les taches disponibles, vous pouvez lui demander de:
* regarder au coordonn√©e x z
* se rendre au coordonn√©e x z
* chercher un objet dans la scene qu'il a apprit au pr√©alable (canard ou balle)
* suivre un objet dans la scene qu'il a apprit au pr√©alable (canard ou balle)

Lorsqu'il suit un objet, il est possible de d√©placer avec son curseur l'objet dans la scene. Pepper essayera de le suivre tant qu'il reste dans son champ de vision.

# Fonctionnement
Il y a deux r√©seaux de neurones qui ont √©t√© impl√©ment√© dans le syst√®me. Un pour la reconnaissance d'image (Perception) et l'autre pour le tchatbot (Communication).

Le dataset de la reconnaissance d'image √† √©t√© g√©n√©r√© √† l'aide de qiBullet. On a tent√© d'extraire des coordonn√©es pour g√©n√© afin d'entrainer notre mod√®le 

# üìú Execution

Plusieurs commandes sont disponibles dans le projet:

* python main.py : lance le projet
* python train perception -g: lance la g√©n√©ration du dataset puis l'apprentissage du model de perception
* python train communication: lance l'apprentissage du model de communication  